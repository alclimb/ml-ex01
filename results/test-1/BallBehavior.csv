Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
50000,1.4146953,50.43550051599587,0.2723251,-0.18764459116630688,-0.18764459116630688,1.3156085,0.024939517,0.00028460252,0.19486748,0.0047438885,1.0
100000,1.4068121,59.44202898550725,0.5017404,2.216473184939888,2.216473184939888,0.34231922,0.024072614,0.00025689485,0.18563159,0.0042830175,1.0
150000,1.3843815,49.13453815261044,1.3535781,3.833760838955641,3.833760838955641,0.17122093,0.023775514,0.00022607874,0.17535956,0.003770442,1.0
200000,1.3605282,50.15660184237461,1.7802924,4.388024023555776,4.388024023555776,0.07979069,0.02229548,0.00019530905,0.16510299,0.0032586395,1.0
250000,1.3367536,62.79007633587786,2.0482824,5.394223248382258,5.394223248382258,0.04604557,0.025400897,0.00016449389,0.15483126,0.002746081,1.0
300000,1.31532,72.10279001468429,2.2130113,5.959324775684264,5.959324775684264,0.037066095,0.02376682,0.00013366374,0.14455457,0.002233273,1.0
